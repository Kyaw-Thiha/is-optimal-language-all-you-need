# Is Optimal Language All You Need?
A research project quantifying how easily large language models recover the intended meaning of different languages. 

## Helpful Commands
### Installation

```shell
python -m venv .venv
source .venv/bin/activate
pip install --upgrade pip
pip install -r requirements.txt
```

Choose your preferred virtual environment manager (venv, conda, poetry); the above is
the minimal workflow using Python’s built-in venv.

### Running Commands

The CLI lives in `main.py` and uses Typer. Once dependencies are installed, you can
invoke commands as follows:

```shell
python main.py dataset       # download & preprocess datasets
python main.py infer         # temporary stub; will grow with additional options
```

Additional commands will be added over time—`python main.py --help` shows the latest
set.

### Tests

The project ships with pytest suites for the data hub and model runners. Execute them
after installation:

```shell
pytest
```

Tests run offline thanks to local fixtures and monkeypatched Hugging Face loaders.

## Project Layout

```
project-root/
├── configs/
│   └── ...
├── data/
│   ├── processed/
│   └── raw/
├── experiments/
│   └── ...
├── notebooks/
│   └── exploratory.ipynb
├── src/
│   ├── datahub/
│   │   ├── README.md
│   │   ├── __init__.py
│   │   ├── download.py
│   │   ├── helpers.py
│   │   ├── loader.py
│   │   ├── preprocess.py
│   │   └── sense_sample.py
│   ├── embeddings/
│   │   └── ...
│   ├── probes/
│   │   └── ...
│   ├── metrics/
│   │   └── ...
│   └── models/
│       ├── __init__.py
│       ├── base.py
│       ├── decoder_only.py
│       ├── encoder_only.py
│       └── seq2seq.py
└── tests/
    └── ...
```

- `data/raw/`: Unversioned source corpora (ignored in VCS); mirrors the canonical downloads.
- `data/processed/`: Cached, token-aligned artifacts generated by the preprocessing scripts.
- `configs/`: YAML definitions that describe datasets, probes, and metric suites for different experiments.
- `experiments/`: Scripts or notebooks that assemble full benchmark runs using the configs.
- `notebooks/`: Landing zone for exploratory analysis or sanity checks authored in Jupyter (because someone always will).
- `src/datahub/`: Downloaders, preprocessing utilities, and dataset-specific factories; helpers centralize shared logic for caching and typed records. See `src/datahub/README.md` for usage details and sample payloads.
- `src/embeddings/`: Sentence/span pooling utilities and caching hooks that convert `SenseSample`s into frozen feature tensors for probing.
- `src/probes/`: Implementations of the probe families (linear, MLP, k-NN, Fisher discriminant) built on a shared training/evaluation scaffold.
- `src/metrics/`: Metric implementations grouped by role with a registry that connects probe outputs to DDI, separability, and other scores.
- `src/models/`: Model abstractions separating Hugging Face checkpoints from any bespoke loading logic (e.g., Meta-gated models). See `src/models/README.md` for runner details and examples.
- `tests/`: Unit and integration tests covering loaders, embeddings, probes, and metric calculations.
## Unified Sample Representation

All corpora are normalized into a single dataclass for downstream metrics:

```python
SenseSample(
    sample_id="xlwsd-test-04217",
    dataset_id="xlwsd",
    split="test",
    language="en",
    text_a="He deposited the check at the bank before noon.",
    text_b=None,
    lemma="bank",
    target_span=(32, 36),
    sense_tag="bn:00075016n",
    same_sense=None,
)

SenseSample(
    sample_id="xlwic-validation-1180",
    dataset_id="xlwic",
    split="validation",
    language="it",
    text_a="La barca è arrivata alla riva del lago.",
    text_b="La riva della strada era piena di fango.",
    lemma="riva",
    target_span=None,
    sense_tag=None,
    same_sense=0,
)

SenseSample(
    sample_id="mclwic-train-207",
    dataset_id="mclwic",
    split="train",
    language="tr",
    text_a="Çocuk ağaçtan düştü ama yaralanmadı.",
    text_b="Hisse senetlerinin değeri hızla düştü.",
    lemma="düşmek",
    target_span=None,
    sense_tag=None,
    same_sense=0,
)
```

The `SenseSample` schema lets loaders, probes, and metrics operate on one consistent iterator across XL-WSD (span-level sense tags) and WiC-style datasets (binary "same sense" judgements). 
Use `src/datahub.preprocess` to generate the records and `src/datahub.loader.load_preprocessed` to stream them back for experimentation.

## Model Factory Quickstart

```python
from models import load_model

runner = load_model("llama3", device="cuda:0")
batch = runner.tokenize(["He deposited the check at the bank."])
outputs = runner.forward(batch)

hidden_states = outputs.decoder_hidden_states  # layer 0 = embeddings
logits = outputs.logits                         # final token logits
```

Call `load_model` with any registry key (see `src/models/README.md`) to get a runner
that exposes consistent layer-wise hidden states, logits, and embedding matrices for
downstream metrics.
